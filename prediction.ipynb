{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import pandas as pd\n",
    "print(tf.__version__)\n",
    "assert(tf.__version__.startswith(\"2.\"))\n",
    "\n",
    "from tensorflow.keras import layers, backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import backend\n",
    "assert(tf.__version__.startswith(\"2.\"))\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "       \n",
    "# Tensorboard\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Helper libraries\n",
    "# from w266_common import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "# From sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "from nltk import tokenize\n",
    "from joblib import load\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/okcat/Documents/MIDS/text-formality-classifier\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, file):\n",
    "    sentences = []\n",
    "    f = open(path+file, \"r\")\n",
    "    for line in f:\n",
    "        sentences.append(line)\n",
    "        #sentences.append(re.findall(r\"[\\w']+|[.,!?;-]\", line.split(\"\\n\")[0]))\n",
    "    # print(f.read())\n",
    "    f.close()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104562, 104562)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1 = '../GYAFC_Corpus/Entertainment_Music/' \n",
    "path2 = '../GYAFC_Corpus/Family_Relationships/'\n",
    "\n",
    "informal = read_file(path1, file='train/informal') + read_file(path2, file='train/informal')\n",
    "formal = read_file(path1, file='train/formal') + read_file(path2, file='train/formal')\n",
    "\n",
    "len(informal), len(formal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the movie The In-Laws not exactly a holiday movie but funny and good!\\n',\n",
       " 'that page did not give me viroses(i think)\\n',\n",
       " 'of corse i be wachin it evry day, my fav charachter is Inuasha\\n',\n",
       " 'runescape.com (my kids love it) & funbrain.com  (educational)\\n',\n",
       " \"Is he gay?He was on Late Night with Conan O'Brien and he seemed pretty gay\\n\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informal[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =[\"the movie The In-Laws not exactly a holiday movie but funny and good!\",\n",
    " \"that page did not give me viroses(i think)\",\n",
    " 'of corse i be wachin it evry day, my fav charachter is Inuasha',\n",
    " 'runescape.com (my kids love it) & funbrain.com  (educational)',\n",
    " \"Is he gay?He was on Late Night with Conan O'Brien and he seemed pretty gay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred(texts, pred):\n",
    "    for txt, p in zip(texts, pred):\n",
    "        print(\"formal: \", txt) if p == 0 else print(\"informal: \", txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na√≠ve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informal:  the movie The In-Laws not exactly a holiday movie but funny and good!\n",
      "formal:  that page did not give me viroses(i think)\n",
      "informal:  of corse i be wachin it evry day, my fav charachter is Inuasha\n",
      "informal:  runescape.com (my kids love it) & funbrain.com  (educational)\n",
      "informal:  Is he gay?He was on Late Night with Conan O'Brien and he seemed pretty gay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "NB = load(\"model/raw_nb.jbl\")\n",
    "pred = NB.predict(texts)\n",
    "print_pred(texts, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Informal:  81325  words,  77.77682140739465 %\n",
      "Correct Formal:  77106  words,  73.74189476100304 %\n"
     ]
    }
   ],
   "source": [
    "n = len(inf_nb)\n",
    "inf_nb = NB.predict(informal)\n",
    "f_nb = NB.predict(formal)\n",
    "\n",
    "print('Correct Informal: ', sum(inf_nb), ' words, ', 100 * sum(inf_nb)/n, '%')\n",
    "print('Correct Formal: ', n - sum(f_nb), ' words, ', 100 * (1 - sum(f_nb)/n), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informal:  the movie The In-Laws not exactly a holiday movie but funny and good!\n",
      "formal:  that page did not give me viroses(i think)\n",
      "informal:  of corse i be wachin it evry day, my fav charachter is Inuasha\n",
      "informal:  runescape.com (my kids love it) & funbrain.com  (educational)\n",
      "informal:  Is he gay?He was on Late Night with Conan O'Brien and he seemed pretty gay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator HashingVectorizer from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "LG = load(\"model/raw_lg.jbl\")\n",
    "pred = LG.predict(texts)\n",
    "print_pred(texts, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Informal:  79740  words,  76.26097435014633 %\n",
      "Correct Formal:  81182  words,  77.64006044260822 %\n"
     ]
    }
   ],
   "source": [
    "inf_nb = LG.predict(informal)\n",
    "f_nb = LG.predict(formal)\n",
    "\n",
    "print('Correct Informal: ', sum(inf_nb), ' words, ', 100 * sum(inf_nb)/n, '%')\n",
    "print('Correct Formal: ', n - sum(f_nb), ' words, ', 100 * (1 - sum(f_nb)/n), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informal:  the movie The In-Laws not exactly a holiday movie but funny and good!\n",
      "informal:  that page did not give me viroses(i think)\n",
      "informal:  of corse i be wachin it evry day, my fav charachter is Inuasha\n",
      "informal:  runescape.com (my kids love it) & funbrain.com  (educational)\n",
      "informal:  Is he gay?He was on Late Night with Conan O'Brien and he seemed pretty gay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/okcat/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "DT = load(\"model/raw_dt.jbl\")\n",
    "pred = DT.predict(texts)\n",
    "print_pred(texts, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Informal:  104562  words,  100.0 %\n",
      "Correct Formal:  0  words,  0.0 %\n"
     ]
    }
   ],
   "source": [
    "inf_nb = DT.predict(informal)\n",
    "f_nb = DT.predict(formal)\n",
    "\n",
    "print('Correct Informal: ', sum(inf_nb), ' words, ', 100 * sum(inf_nb)/n, '%')\n",
    "print('Correct Formal: ', n - sum(f_nb), ' words, ', 100 * (1 - sum(f_nb)/n), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1a263a4680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "formal:  the movie The In-Laws not exactly a holiday movie but funny and good!\n",
      "formal:  that page did not give me viroses(i think)\n",
      "formal:  of corse i be wachin it evry day, my fav charachter is Inuasha\n",
      "informal:  runescape.com (my kids love it) & funbrain.com  (educational)\n",
      "formal:  Is he gay?He was on Late Night with Conan O'Brien and he seemed pretty gay\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = 20000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences_new = tokenizer.texts_to_sequences(texts)\n",
    "new_texts = pad_sequences(sequences_new, maxlen = 1000) \n",
    "\n",
    "model = load_model(\"model/LSTM.h5\") \n",
    "pred = np.argmax(model.predict(new_texts), axis=1)\n",
    "print_pred(texts, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 20000)\n",
    "tokenizer.fit_on_texts(informal)\n",
    "sequences_new = tokenizer.texts_to_sequences(informal)\n",
    "new_texts = pad_sequences(sequences_new, maxlen = 1000) \n",
    "\n",
    "inf = np.argmax(model.predict(new_texts), axis=1)\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 20000)\n",
    "tokenizer.fit_on_texts(formal)\n",
    "sequences_new = tokenizer.texts_to_sequences(formal)\n",
    "new_texts = pad_sequences(sequences_new, maxlen = 1000) \n",
    "\n",
    "f = np.argmax(model.predict(new_texts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Informal:  65148  words,  62.30561771963046 %\n",
      "Correct Formal:  45702  words,  43.708039249440525 %\n"
     ]
    }
   ],
   "source": [
    "print('Correct Informal: ', sum(inf), ' words, ', 100 * sum(inf)/n, '%')\n",
    "print('Correct Formal: ', n - sum(f), ' words, ', 100 * (1 - sum(f)/n), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
